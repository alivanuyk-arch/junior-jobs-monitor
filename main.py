import requests
import json
import feedparser
import os
import asyncio
from datetime import datetime

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ====================
TELEGRAM_TOKEN = "8285832122:AAE0BdJxpF3kigE3Ljnj0DbWmDbVjFeQcKs"
CHAT_ID = "7745305298"

RSS_SOURCES = {
    'habr': 'https://habr.com/ru/rss/all/all/?fl=ru',
    'vc_ru': 'https://vc.ru/rss', 
}

RELEVANT_KEYWORDS = [
    'python', 'junior', '–¥–∂—É–Ω–∏–æ—Ä', '—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ', '–∫–∞—Ä—å–µ—Ä–∞',
    '—Ä–∞–±–æ—Ç–∞', 'IT', '—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç', '–Ω–∞—á–∏–Ω–∞—é—â–∏–π'
]

# ==================== –û–ë–©–ò–ï –§–£–ù–ö–¶–ò–ò ====================

def get_vacancies():
    """–ü–∞—Ä—Å–∏–º –≤–∞–∫–∞–Ω—Å–∏–∏ —Å HH.ru"""
    try:
        url = "https://api.hh.ru/vacancies?text=python&experience=noExperience"
        data = requests.get(url, timeout=10)
        return data.json()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–π: {e}")
        return None

def filter_vacancies(data):
    """–§–∏–ª—å—Ç—Ä—É–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –¥–∂—É–Ω–æ–≤"""
    junior_vacancies = []
    if not data:
        return []
    
    for vacancy in data['items']:
        if (vacancy['id'] and vacancy['id'].strip() != "" and 
            any(keyword in vacancy['name'].lower() for keyword in ['data', 'bi', 'etl', 'analytics'])):
            junior_vacancies.append(vacancy)
    return junior_vacancies

def save_vacancies(junior_vacancies):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏"""
    new_vacancies = []
    try:
        with open('old_vacancies.json', 'r') as f:
            old_vacancies = json.load(f) 
    except FileNotFoundError:
        old_vacancies = []
    
    old_ids = {v['id'] for v in old_vacancies}
    for vacancy in junior_vacancies:
        if vacancy['id'] not in old_ids:
            new_vacancies.append(vacancy)
       
    with open('old_vacancies.json', 'w') as f:
        json.dump(junior_vacancies, f)
    return new_vacancies

def get_news():
    """–ü–∞—Ä—Å–∏–º –Ω–æ–≤–æ—Å—Ç–∏"""
    all_new_articles = []
    
    try:
        with open('previous_news.json', 'r', encoding='utf-8') as f:
            previous_articles = json.load(f)
    except FileNotFoundError:
        previous_articles = []
    
    previous_titles = {a['title'] for a in previous_articles}
    current_articles = previous_articles.copy()
    
    for source_name, rss_url in RSS_SOURCES.items():
        try:
            feed = feedparser.parse(rss_url)
            raw_articles = []
            for entry in feed.entries[:10]:
                raw_articles.append({
                    'title': entry.title,
                    'url': entry.link,
                    'source': source_name
                })
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            relevant_articles = []
            for article in raw_articles:
                title_lower = article['title'].lower()
                if any(keyword in title_lower for keyword in RELEVANT_KEYWORDS):
                    relevant_articles.append(article)
            
            # –î–µ–¥—É–±–ª–∏–∫–∞—Ü–∏—è –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–æ–≤—ã–µ
            seen_titles = set()
            for article in relevant_articles:
                short_title = article['title'][:40].lower()
                if short_title not in seen_titles:
                    seen_titles.add(short_title)
                    if article['title'] not in previous_titles:
                        current_articles.append(article)
                        all_new_articles.append(article)
                        previous_titles.add(article['title'])
                        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ {source_name}: {e}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    if all_new_articles:
        with open('previous_news.json', 'w', encoding='utf-8') as f:
            json.dump(current_articles, f, ensure_ascii=False, indent=2)
    
    return all_new_articles

def format_digest(vacancies, news):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–π–¥–∂–µ—Å—Ç"""
    message = "üìä –ï–ñ–ï–î–ù–ï–í–ù–´–ô –î–ê–ô–î–ñ–ï–°–¢ –î–õ–Ø –î–ñ–£–ù–û–í\n\n"
    
    if vacancies:
        message += f"üéØ –í–∞–∫–∞–Ω—Å–∏–∏ ({len(vacancies)}):\n"
        for v in vacancies[:5]:
            message += f"‚Ä¢ {v['name']}\n"
        message += "\n"
    
    if news:
        message += f"üì∞ –ù–æ–≤–æ—Å—Ç–∏ ({len(news)}):\n"
        for n in news[:3]:
            message += f"‚Ä¢ {n['title']}\n"
    
    message += "–£–¥–∞—á–∏ –≤ –ø–æ–∏—Å–∫–∞—Ö! üí™"
    return message

# ==================== –†–ï–ñ–ò–ú 1: –°–ï–†–í–ï–†–ù–ê–Ø –í–ï–†–°–ò–Ø ====================

async def send_telegram_message(text):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram"""
    from telegram import Bot
    bot = Bot(token=TELEGRAM_TOKEN)
    await bot.send_message(chat_id=CHAT_ID, text=text)

def vacancies_etl():
    """ETL –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–π"""
    print("üîÑ –í–∞–∫–∞–Ω—Å–∏–∏: –Ω–∞—á–∏–Ω–∞–µ–º ETL...")
    raw_data = get_vacancies()
    if not raw_data:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–π")
        return []
    
    clean_data = filter_vacancies(raw_data)
    new_vacancies = save_vacancies(clean_data)
    print(f"‚úÖ –í–∞–∫–∞–Ω—Å–∏–∏: {len(new_vacancies)} –Ω–æ–≤—ã—Ö")
    return new_vacancies

def news_etl():
    """ETL –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π"""
    print("üì∞ –ù–æ–≤–æ—Å—Ç–∏: –Ω–∞—á–∏–Ω–∞–µ–º ETL...")
    new_news = get_news()
    print(f"‚úÖ –ù–æ–≤–æ—Å—Ç–∏: {len(new_news)} –Ω–æ–≤—ã—Ö")
    return new_news

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–µ—Ä–≤–µ—Ä–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞"""
    print("üöÄ –ó–ê–ü–£–°–ö –ù–ê –°–ï–†–í–ï–†–ï (–±–µ–∑ Airflow)")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º ETL –ø—Ä–æ—Ü–µ—Å—Å—ã
    vacancies = vacancies_etl()
    news = news_etl()
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–π–¥–∂–µ—Å—Ç
    if vacancies or news:
        message = format_digest(vacancies, news)
        await send_telegram_message(message)
        print("‚úÖ –î–∞–π–¥–∂–µ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Telegram")
    else:
        await send_telegram_message("üì≠ –°–µ–≥–æ–¥–Ω—è –Ω–µ—Ç –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –∏ –Ω–æ–≤–æ—Å—Ç–µ–π")
        print("üì≠ –ù–∏—á–µ–≥–æ –Ω–æ–≤–æ–≥–æ")

# ==================== –†–ï–ñ–ò–ú 2: AIRFLOW DAG ====================
"""
# –†–ê–ó–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–¢–¨ –î–õ–Ø AIRFLOW:

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.models import Variable

# –ö–æ–Ω—Ñ–∏–≥–∏ —á–µ—Ä–µ–∑ Airflow Variables (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞)
# TELEGRAM_TOKEN = Variable.get("telegram_token")
# CHAT_ID = Variable.get("chat_id")

def airflow_vacancies_etl():
    # –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è Airflow
    return vacancies_etl()

def airflow_news_etl():
    return news_etl()

def airflow_send_digest(**context):
    # –õ–æ–≥–∏–∫–∞ —Å XCom –¥–ª—è Airflow
    ti = context['ti']
    vacancies = ti.xcom_pull(task_ids='vacancies_etl') or []
    news = ti.xcom_pull(task_ids='news_etl') or []
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    if vacancies or news:
        message = format_digest(vacancies, news)
        # –í —Ä–µ–∞–ª—å–Ω–æ–º Airflow –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Telegram Hook –∏–ª–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–π –æ–ø–µ—Ä–∞—Ç–æ—Ä
        print(f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram: {len(vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π, {len(news)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        # –†–µ–∞–ª—å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞: await send_telegram_message(message)
    else:
        print("üì≠ –ù–∏—á–µ–≥–æ –Ω–æ–≤–æ–≥–æ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏")

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ DAG
with DAG(
    'daily_jobs_pipeline',
    description='Production ETL pipeline for junior jobs monitoring',
    schedule_interval='@daily',
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['jobs', 'monitoring', 'etl']
) as dag:
    
    vacancies_task = PythonOperator(
        task_id='vacancies_etl',
        python_callable=airflow_vacancies_etl
    )
    
    news_task = PythonOperator(
        task_id='news_etl',
        python_callable=airflow_news_etl
    )
    
    telegram_task = PythonOperator(
        task_id='send_telegram_digest',
        python_callable=airflow_send_digest,
        provide_context=True
    )
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    vacancies_task >> news_task >> telegram_task

"""

# ==================== –ó–ê–ü–£–°–ö ====================

if __name__ == "__main__":
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞
    try:
        # –ü—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å Airflow
        from airflow import DAG
        print("‚úÖ –†–µ–∂–∏–º: Airflow DAG (—Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –±–ª–æ–∫ –≤—ã—à–µ)")
        # DAG –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ, –µ—Å–ª–∏ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω
    except ImportError:
        print("‚úÖ –†–µ–∂–∏–º: –°–µ—Ä–≤–µ—Ä–Ω—ã–π –∑–∞–ø—É—Å–∫")
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä–Ω—É—é –≤–µ—Ä—Å–∏—é
        asyncio.run(main())
